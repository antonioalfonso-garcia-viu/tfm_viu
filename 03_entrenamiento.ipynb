{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sklearn\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "#  cargar algoritmos para aprendizaje supervisado\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel, mutual_info_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "\n",
    "# importar fichero con utilidades propias\n",
    "from commons import myfunctions as myfunc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros a utilizar en el entrenamiento.\n",
    "\n",
    "Se indican los 3 algoritmos de *selección de características* (eval_selector_xxx) y los 3 algoritmos para la _clasificación_ (eval_clasifier_xxx)\n",
    "\n",
    "En *param_distributions* se indicar los parámetros que utilizan los algoritmos en la función RandomSearchCV.\n",
    "\n",
    "Esta celda tiene la etiqueta **parameters** que servirá para poder lanzar los entrenamientos con la utilidad **papermill** pasándole un fichero con los parámetros. \n",
    "\n",
    "Los nuevos parámetros se situarán tras esta celda para tener prevalencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#  ejemplo de parametros para cada conjunto de datos\n",
    "\n",
    "M_TIPO = \"mul_m\"\n",
    "R_FICHERO = \"resultados\"\n",
    "M_FICHERO = \"metricas\"\n",
    "PRE_DATA_FILE = \"rows_transpose_norm_by_gene_id_with_target_num_\"\n",
    "SCORING = \"roc_auc_ovr\" \n",
    "MAX_ITERS = 100\n",
    "SEMILLA = 42\n",
    "\n",
    "# fucnión para iniciar siempre con la misma semilla Mutual Information\n",
    "def mutual_info_classif_state(X, y):\n",
    "    return mutual_info_classif(X, y, random_state=SEMILLA)\n",
    "\n",
    "eval_selector_mi= \"SelectKBest(score_func=mutual_info_classif_state)\"\n",
    "eval_selector_rf= \"SelectFromModel(estimator=RandomForestClassifier(random_state=SEMILLA), threshold=-np.inf)\"\n",
    "eval_selector_anova= \"SelectKBest(score_func=f_classif)\"\n",
    "\n",
    "eval_clasifier_svm= \"SVC(probability=True, random_state=SEMILLA)\"\n",
    "eval_clasifier_rf= \"RandomForestClassifier(random_state=SEMILLA)\"\n",
    "eval_clasifier_lr= \"LogisticRegressionCV(random_state=SEMILLA)\"\n",
    "\n",
    "\n",
    "if M_TIPO.startswith(\"bin_m\"):\n",
    "    myfunc.verbose(f\"Utilizando parámetros de {M_TIPO}\")\n",
    "\n",
    "    eval_selector = eval_selector_rf\n",
    "    eval_clasifier = eval_clasifier_lr\n",
    "\n",
    "    SEMILLA = 6191\n",
    "    M_SELECT = \"RF\"\n",
    "    M_CLASIF = \"LR_L2\"\n",
    "    param_distributions = {'selector__max_features': [50],\n",
    "        'selector__estimator__n_estimators': [10], 'clasifier__solver': ['lbfgs'], 'clasifier__penalty': ['l2'], 'clasifier__max_iter': [10000]}\n",
    "\n",
    "\n",
    "elif M_TIPO.startswith(\"bin_s\"):\n",
    "    myfunc.verbose(f\"Utilizando parámetros de {M_TIPO}\")\n",
    "    \n",
    "    eval_selector = eval_selector_anova\n",
    "    eval_clasifier = eval_clasifier_lr\n",
    "\n",
    "    SEMILLA = 1860\n",
    "    M_SELECT = \"ANOVA\"\n",
    "    M_CLASIF = \"LR_L2\"\n",
    "    param_distributions = {'selector__k': [100], \n",
    "        'clasifier__solver': ['saga'], 'clasifier__penalty': ['l2'], 'clasifier__max_iter': [10000]}\n",
    "\n",
    "elif M_TIPO.startswith(\"mul_m\"):\n",
    "    myfunc.verbose(f\"Utilizando parámetros de {M_TIPO}\")\n",
    " \n",
    "    eval_selector = eval_selector_mi\n",
    "    eval_clasifier = eval_clasifier_lr\n",
    "\n",
    "    SEMILLA = 6191\n",
    "    M_SELECT = \"MI\"\n",
    "    M_CLASIF = \"LR_EN\"\n",
    "    param_distributions = {'selector__k': [100],\n",
    "        'clasifier__solver': ['saga'], 'clasifier__penalty': ['elasticnet'], 'clasifier__max_iter': [10000], 'clasifier__l1_ratios': [[0.2]]}\n",
    "\n",
    "else:\n",
    "    # M_TIPO.startswith(\"mul_s\"):\n",
    "    myfunc.verbose(f\"Utilizando parámetros de {M_TIPO}\")\n",
    "\n",
    "    eval_selector = eval_selector_anova\n",
    "    eval_clasifier = eval_clasifier_lr\n",
    "\n",
    "    SEMILLA = 1860\n",
    "    M_SELECT = \"ANOVA\"\n",
    "    M_CLASIF = \"LR_L2\"\n",
    "    param_distributions = {'selector__k': [100], \n",
    "        'clasifier__solver': ['saga'], 'clasifier__penalty': ['l2'], 'clasifier__max_iter': [10000]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construir el nombre del fichero con el conjutno de datos según el tipo de clasificación binaria o multiclase\n",
    "DATA_FILE = PRE_DATA_FILE + M_TIPO\n",
    "\n",
    "# si viene \"None\" en el parámetro max_depth, se le quitan las comillas para que no sea entendido por el algoritmo como un texto\n",
    "if \"clasifier__max_depth\" in param_distributions:\n",
    "    param_distributions['clasifier__max_depth'] = [None if x == 'None' else x for x in param_distributions['clasifier__max_depth']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignar los algoritmos que se utilizarán en la función RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algor_selector=eval(eval_selector)\n",
    "algor_clasifier=eval(eval_clasifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprobar el entorno y leer fichero de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "myfunc.reset_vars()\n",
    "\n",
    "myfunc.NOTEBK_FILENAME = myfunc.get_nb_name()\n",
    "\n",
    "myfunc.check_enviroment(myfunc.DATA_DIR, myfunc.CFDNA_DIR, myfunc.GENCODE_DIR, myfunc.H5_DIR, myfunc.LOG_DIR, myfunc.CSV_DIR, myfunc.MODEL_DIR, myfunc.EXEC_DIR, myfunc.MET_DIR)\n",
    "\n",
    "# Leer fichero con las muestras\n",
    "df_t = myfunc.read_h5_to_df(DATA_FILE, myfunc.H5_DIR)\n",
    "display(df_t.groupby(\"target\").size())\n",
    "print(\"Shape df:\",df_t.shape)\n",
    "\n",
    "# Separar caracteristicas/genes de las etiquetas/tipos de cáncer\n",
    "X = df_t.iloc[:, :-1]  # Todas las columnas excepto la última\n",
    "y = df_t.iloc[:, -1]  # La última columna contiene los identificadores de los tipos de cáncer\n",
    "\n",
    "#  Crear el conjunto de datos de entrenamiento y de pruebas, y se fija la semilla para siempre coger el mismo juego de muestras\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(\"Shape X_train:\",X_train.shape)\n",
    "print(\"Shape X_test:\",X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selección de características, clasificación y entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunc.verbose(\"Iniciando entrenamiento\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEMILLA)\n",
    "\n",
    "# Crear el pipeline para el flujo de tareas\n",
    "tasks_pipeline = Pipeline([\n",
    "    ('selector', algor_selector),\n",
    "    ('clasifier', algor_clasifier)\n",
    "])\n",
    "\n",
    "# MAX_ITERS puede limitar el número de iteraciones si son excesivas para las combinaciones de parámetros buscando un óptimo local, \n",
    "# sino funcionaría como GridSearchCV al revisar todas las cominaciones de los parámetros\n",
    "num_iteraciones = 1\n",
    "num_iteraciones = num_iteraciones * np.prod([len(elemento1) for _, elemento1 in param_distributions.items()])\n",
    "max_iteraciones = num_iteraciones if num_iteraciones <= MAX_ITERS else MAX_ITERS\n",
    "print(\"num_iter:\",num_iteraciones,\", max_iter:\",max_iteraciones)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    tasks_pipeline, \n",
    "    param_distributions, \n",
    "    n_iter=max_iteraciones,\n",
    "    scoring=SCORING,\n",
    "    cv=kf,\n",
    "    verbose=3, \n",
    "    random_state=SEMILLA, \n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "# Entrenar el modelo\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Ver los mejores hiperparámetros encontrados\n",
    "print(f'Mejores Hiperparámetros: {random_search.best_params_}')\n",
    "print(f'Mejor Puntuación: {random_search.best_score_:.4f}')\n",
    "\n",
    "# Nos quedamos con el mejor modelo para ver las métricas\n",
    "mejor_modelo = random_search.best_estimator_\n",
    "\n",
    "myfunc.verbose(\"Fin entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar el modelo incluyendo la semilla utilizada, el tipo de conjunto de datos utilizado y los identificadores de los algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichero_modelo = str.replace(\"modelo_\"+str(SEMILLA).zfill(4)+\"_\"+M_TIPO+\"_\"+M_SELECT+\"_\"+M_CLASIF+\".pkl\", \" \", \"_\")\n",
    "\n",
    "myfunc.save_modelo(mejor_modelo, myfunc.MODEL_DIR, fichero_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver resultados del las iteraciones hechas por RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunc.ver_resultados_search(random_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver métricas del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if M_TIPO.startswith(\"bin\"):\n",
    "    myfunc.ver_metricas(mejor_modelo, X_test, y_test)\n",
    "else:\n",
    "    myfunc.ver_metricas_multi(mejor_modelo, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if M_TIPO.startswith(\"bin\"):\n",
    "    myfunc.save_metricas_to_csv(random_search, X_test, y_test, M_TIPO, M_SELECT, M_CLASIF, total_time, SEMILLA, myfunc.MET_DIR, M_FICHERO, fichero_modelo)\n",
    "else:\n",
    "    myfunc.save_metricas_multi_to_csv(random_search, X_test, y_test, M_TIPO, M_SELECT, M_CLASIF, total_time, SEMILLA, myfunc.MET_DIR, M_FICHERO, fichero_modelo)\n",
    "\n",
    "df1=myfunc.read_metricas_to_df(myfunc.MET_DIR,M_FICHERO)\n",
    "\n",
    "display(df1.sort_values(\"datetime\", ascending=False)[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichero_resultados=R_FICHERO+\"_\"+M_TIPO+\"-\"+M_SELECT+\"-\"+M_CLASIF+\".csv\"\n",
    "myfunc.save_resultados_to_csv(M_TIPO, M_SELECT, M_CLASIF,  random_search, myfunc.MET_DIR, fichero_resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalización del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.datetime.now()\n",
    "total_time = end_time - start_time\n",
    "myfunc.verbose(f\"Notebook ha tardado {total_time.seconds} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
