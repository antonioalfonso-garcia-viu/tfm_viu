{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas de las semillas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al estar las muestras equilibradas para el entramiento de los modelos, la exactitud (accuracy), la precisión (precision), la sensibilidad (recall) y la puntuación F1 adquieren más relevancia y se vuelven más confiables para comparar el rendimiento de los modelos. \n",
    "\n",
    "El equilibrio de las clases reduce el sesgo hacia la clase mayoritaria, que es una de las principales limitaciones de estas métricas en conjuntos de datos desequilibrados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import psutil\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from commons import myfunctions as myfunc\n",
    "\n",
    "start_time = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer fichero con métricas de los modelos entrenados con semilla 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "archivo1= os.path.join(myfunc.MET_DIR, \"metricas_0042.csv\")\n",
    "\n",
    "fichero1 = os.path.basename(archivo1)\n",
    "carpeta1 = os.path.dirname(archivo1)\n",
    "\n",
    "df_tmp = myfunc.read_csv_to_df_spa(fichero1, carpeta1)[['tipo', 'select', 'clasific', 'accuracy', 'precision', 'recall', 'f1_score', 'roc_auc', 'roc_auc_ovr','fichero_modelo','indices_auc','indices_jaccard']]\n",
    "df_tmp['tipo_select_clasific'] = df_tmp['tipo'] + '-' + df_tmp['select'] + '-' + df_tmp['clasific']\n",
    "df_tmp['select_clasific'] = df_tmp['select'] + '-' + df_tmp['clasific']\n",
    "df_tmp['auc'] = df_tmp['roc_auc'].fillna(0) + df_tmp['roc_auc_ovr'].fillna(0)\n",
    "\n",
    "df_c = df_tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dibujar_grafico_barras(df1):\n",
    "    df_g = df1.sort_values(by=[\"tipo_select_clasific\",\"accuracy\",\"precision\"], ascending=True).copy().reset_index()\n",
    "\n",
    "    ax = df_g.plot(kind='barh', x='tipo_select_clasific', figsize=(10, 8), width=0.9)\n",
    "    ax.xaxis.set_major_locator(plt.MultipleLocator(0.1))  \n",
    "    ax.grid(True, which='both', axis='x', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # coger datos para dibujar una línea vertical que indique el valor mayor del accuracy\n",
    "    max_accuracy = df_g['accuracy'].max()  \n",
    "    max_accuracy_index = df_g['accuracy'].idxmax()  \n",
    "    ax.axvline(x=max_accuracy, color='red', linestyle='--', linewidth=1) \n",
    "\n",
    "    for i, bar in enumerate(ax.patches):\n",
    "        if i == max_accuracy_index:  \n",
    "            ax.annotate(f'Max Accuracy: {max_accuracy:.4f}', \n",
    "                        xy=(max_accuracy, bar.get_y() + bar.get_height()/2),\n",
    "                        xytext=(3, 0), textcoords='offset points',\n",
    "                        ha='left', va='center')\n",
    "\n",
    "    ax.set_xlabel('Métricas')\n",
    "    ax.set_title('Comparación de métricas de diferentes algoritmos')\n",
    "    ax.set_yticklabels(df_g['tipo_select_clasific'])\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "    ax.legend(title='Métricas', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_c.sort_values([\"tipo\",\"select\",\"clasific\"])\n",
    "columnas = [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"auc\"]\n",
    "df_suma = df1.groupby(\"tipo_select_clasific\")[columnas].sum()\n",
    "df_merge = df_suma.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas para los modelos de clasificación binaria con muestras reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunc.verbose(\"Valores de los modelos con el conjunto de datos bin_s, solo muestras reales\")\n",
    "\n",
    "df1 = df_merge[df_merge.index.str.startswith(\"bin_s\")]\n",
    "\n",
    "display(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibujar_grafico_barras(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas para los modelos de clasificación binaria con muestras reales y sintéticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunc.verbose(\"Valores de los modelos con el conjunto de datos bin_m, muestras reales y sintéticas\")\n",
    "\n",
    "df1=df_merge[df_merge.index.str.startswith(\"bin_m\")]\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibujar_grafico_barras(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas para los modelos de clasificación multicáncer con muestras reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunc.verbose(\"Valores de los modelos con el conjunto de datos mul_s, solo muestras reales\")\n",
    "\n",
    "df1=df_merge[df_merge.index.str.startswith(\"mul_s\")]\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibujar_grafico_barras(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas para los modelos de clasificación multicáncer con muestras reales y sintéticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunc.verbose(\"Valores de los modelos con el conjunto de datos mul_s, muestras reales y sintéticas\")\n",
    "\n",
    "df1=df_merge[df_merge.index.str.startswith(\"mul_m\")]\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibujar_grafico_barras(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columnas que interesan y funciones de mínimos para las desviaciones y de máximos para el resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_suma = [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"auc\"] \n",
    "\n",
    "\n",
    "def get_max_by_column(df):\n",
    "  max_by_column = {}\n",
    "  for column in df.columns:\n",
    "    max_by_column[column] = df[column].idxmax(), df[column].max()\n",
    "\n",
    "  return max_by_column\n",
    "\n",
    "\n",
    "def get_min_by_column(df):\n",
    "  min_by_column = {}\n",
    "  for column in df.columns:\n",
    "    min_by_column[column] = df[column].idxmin(), df[column].min()\n",
    "\n",
    "  return min_by_column\n",
    "\n",
    "\n",
    "def mostrar_mejores(tipo1, estadistico1, df1, orden_columnas=[\"accuracy\"],ordenacion1=False):\n",
    "  df_tipo = df1.query(f\"tipo_select_clasific.str.startswith('{tipo1}')\")\n",
    "  if ordenacion1 == False:\n",
    "    # búsqueda de la mayor media\n",
    "    valores1 = pd.DataFrame(get_max_by_column(df_tipo))\n",
    "  else:\n",
    "    # búsqueda de la mínima desviación\n",
    "    valores1 = pd.DataFrame(get_min_by_column(df_tipo))\n",
    "\n",
    "  algoritmos = valores1.iloc[0].unique()\n",
    "  columnas = df_tipo.columns\n",
    "  df_tipo = df_tipo.round(4)\n",
    "  \n",
    "  myfunc.verbose(f\"Algoritmos en primera posicion por alguna de sus columnas para conjunto de datos {tipo1} y estadístico {estadistico1}\")\n",
    "\n",
    "  display(df_tipo[df_tipo.index.isin(algoritmos)].sort_values(orden_columnas, ascending=ordenacion1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumen de los mejores algoritmos para cada conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orden_columnas=[\"accuracy\", \"precision\", \"recall\"]\n",
    "tipo1 = 'bin_s'\n",
    "mostrar_mejores(tipo1, \"media\", df_merge[columns_suma], orden_columnas)\n",
    "tipo1 = 'bin_m'\n",
    "mostrar_mejores(tipo1, \"media\", df_merge[columns_suma], orden_columnas)\n",
    "tipo1 = 'mul_s'\n",
    "mostrar_mejores(tipo1, \"media\", df_merge[columns_suma], orden_columnas)\n",
    "tipo1 = 'mul_m'\n",
    "mostrar_mejores(tipo1, \"media\", df_merge[columns_suma], orden_columnas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalización del notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.datetime.now()\n",
    "total_time = end_time - start_time\n",
    "myfunc.verbose(f\"Notebook ha tardado {total_time} segundos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
